{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning Final Project\n",
    "\n",
    "## Team member: Mahamitra Jagadheshkumar,  Xikun Yuan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The goal of this project is to classify eletro cardiograph signals (ECG) to see if a person has normal or arrhythmic heartbeats.\n",
    "\n",
    "#### The data is from MIT-BIH arrhythmia database.\n",
    "\n",
    "#### The format of data is a .dat file. The annotation (labels) from actual doctors is in the .atr file. \n",
    "\n",
    "#### To read the .dat file and .atr files, the python package wfdb is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function \"extract_epochs\" below converts a continous data stream into epochs for machine learning.\n",
    "\n",
    "#### Based on the annotation from the doctor, we identify the center of each heart beat.\n",
    "\n",
    "#### We take 150 samples before the center of the heart beat, and 150 samples after the heart beat\n",
    "\n",
    "#### Since the sampling rate is 360 Hz, we are capturing one heart beat per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 300, 2)\n",
      "(49,)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "def extract_epochs(signal, annotation):\n",
    "    epochs = None\n",
    "    labels = []\n",
    "    symbols = annotation.symbol\n",
    "    timepoints = annotation.sample\n",
    "    for i in range(len(timepoints)):\n",
    "        if i < 3:\n",
    "            continue\n",
    "        timepoint = timepoints[i]\n",
    "        if i == 0:\n",
    "            prev_timepoint = 0\n",
    "        else:\n",
    "            prev_timepoint = timepoints[i-1]\n",
    "#         print(\"prev_time point is {}, timepoint is{}\".format(prev_timepoint, timepoint))\n",
    "            \n",
    "        label = symbols[i-1]\n",
    "        \n",
    "        \n",
    "        if epochs is None:\n",
    "            epochs = signal[timepoint - 150: timepoint + 150, :]\n",
    "        elif epochs.shape[0] == 300:\n",
    "            epochs = np.stack((epochs, signal[timepoint - 150: timepoint + 150, :]))\n",
    "        else:\n",
    "            epochs = np.concatenate((epochs, signal[timepoint - 150: timepoint + 150, :].reshape(1, 300, 2)),axis = 0)\n",
    "\n",
    "        labels.append(label)\n",
    "    return epochs, labels\n",
    "\n",
    "\n",
    "\n",
    "#reading one file to look at the size of training epochs\n",
    "f = '100'\n",
    "filename = 'C:\\\\Users\\\\Kun\\\\ecg\\\\' + f\n",
    "record = wfdb.rdsamp(filename, sampto = 15000)\n",
    "signal, fields = wfdb.srdsamp(filename, sampfrom=800)\n",
    "annotation = wfdb.rdann(filename, 'atr', sampto = 15000)\n",
    "epochs, labels= extract_epochs(signal, annotation)\n",
    "epochs = np.array(epochs)\n",
    "labels = np.array(labels)\n",
    "print(epochs.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(4,1))\n",
    "# gs  = matplotlib.gridspec.GridSpec(4, 1)\n",
    "# ax0 = plt.subplot(gs[0])\n",
    "# ax1 = plt.subplot(gs[1])\n",
    "# ax2 = plt.subplot(gs[2])\n",
    "# ax3 = plt.subplot(gs[3])\n",
    "\n",
    "# fig.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "# ax1.plot(epochs[4])\n",
    "# ax2.plot(epochs[5])\n",
    "# ax3.plot(epochs[6])\n",
    "# ax0.plot(epochs[7])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code below iterates through all the data files and makes them into epochs and aggregates them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8394, 300, 2)\n",
      "(8394,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files = ['100','101','102','103','104','105', '106', '107','108', '109','111','112','113','114','115', '116','117','118','119', '121','122','123',\n",
    "         '124', '200','201','202','203','205','207','208','209',\n",
    "        '210','212','213','214','215','217','219','220','221',\n",
    "        '223','228','230','231','232','233','234']\n",
    "labels_total = []\n",
    "epochs_total = None\n",
    "\n",
    "for f in files:\n",
    "    filename = 'C:\\\\Users\\\\Kun\\\\ecg\\\\' + f\n",
    "\n",
    "    signal, fields = wfdb.srdsamp(filename, sampfrom = 0)\n",
    "    annotation = wfdb.rdann(filename, 'atr', sampto = 50000)\n",
    "    epochs, labels= extract_epochs(signal, annotation)\n",
    "    \n",
    "    if epochs_total is None:\n",
    "        epochs_total = epochs\n",
    "    else:\n",
    "        epochs_total = np.concatenate((epochs_total, epochs))\n",
    "    labels_total = labels_total + labels\n",
    "\n",
    "labels_total = np.array(labels_total)\n",
    "    \n",
    "print(epochs_total.shape)\n",
    "print(labels_total.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function \"count_occurance\" below counts the number of samples for each class.\n",
    "\n",
    "#### As we can see from the output, there are way more normal hearbeats than other arrhythmic heartbeats.\n",
    "\n",
    "#### We have to balance the samples for each class to prevent overfitting to one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the occurance of ! is: 44\n",
      "the occurance of \" is: 27\n",
      "the occurance of + is: 90\n",
      "the occurance of / is: 522\n",
      "the occurance of A is: 114\n",
      "the occurance of F is: 51\n",
      "the occurance of L is: 568\n",
      "the occurance of N is: 5755\n",
      "the occurance of Q is: 3\n",
      "the occurance of R is: 553\n",
      "the occurance of V is: 532\n",
      "the occurance of [ is: 2\n",
      "the occurance of ] is: 2\n",
      "the occurance of a is: 4\n",
      "the occurance of e is: 1\n",
      "the occurance of f is: 69\n",
      "the occurance of x is: 2\n",
      "the occurance of | is: 18\n",
      "the occurance of ~ is: 37\n"
     ]
    }
   ],
   "source": [
    "def count_occurance(labels_total):\n",
    "#     labels_total = labels_total.tolist()\n",
    "    unique_label, occurance = np.unique(labels_total, return_counts = True)\n",
    "    for i in range(len(unique_label)):\n",
    "        print(\"the occurance of {} is: {}\".format(unique_label[i], occurance[i]))\n",
    "        \n",
    "count_occurance(labels_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since most of the heartbeats will be normal, we have to control the number of normal samples, otherwise the model will overfit to \"normal\" and classify everything to be \"normal.\"\n",
    "\n",
    "#### We limit the max number of normal heart beat to be 700, since next most frequent class is \"L\", 568.\n",
    "\n",
    "#### Some classes, such as \"e\", \"a\", \"[\", \"]\" are too rare. Therefore we only take 6 of the most common classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the occurance of / is: 522\n",
      "the occurance of A is: 114\n",
      "the occurance of L is: 568\n",
      "the occurance of N is: 701\n",
      "the occurance of R is: 553\n",
      "the occurance of V is: 532\n"
     ]
    }
   ],
   "source": [
    "count_N = 0\n",
    "max_N = 700\n",
    "epochs_new = None\n",
    "labels_new = list()\n",
    "for index, epoch in enumerate(epochs_total):\n",
    "    if labels_total[index] not in ['/', 'A','L','N','R','V']:\n",
    "        continue\n",
    "    epoch = epoch.reshape(1, 300, 2)\n",
    "    if count_N > max_N and labels_total[index] == 'N':\n",
    "        continue\n",
    "    if labels_total[index] == 'N':\n",
    "        count_N = count_N +1\n",
    "\n",
    "    if epochs_new is None:\n",
    "        epochs_new = epoch\n",
    "    else:\n",
    "        epochs_new = np.concatenate((epochs_new, epoch))\n",
    "\n",
    "        \n",
    "    labels_new = labels_new + list(labels_total[index])\n",
    "\n",
    "count_occurance(labels_new)\n",
    "labels_new = np.array(labels_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are taking a naive approach, fitting the time series directly into logistic regression.\n",
    "\n",
    "#### Under 10-fold cross validation, the accuracy is only 53 percent, as expected.\n",
    "\n",
    "#### This is because when the time series is shifted even a little bit, the classification of due to logistic regression can vary greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2990, 300, 2)\n",
      "Classification accuracy: 0.422659 / Chance level: 1.000000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          /       0.47      0.65      0.55       110\n",
      "          A       0.00      0.00      0.00        15\n",
      "          L       0.47      0.12      0.20       130\n",
      "          N       0.31      0.69      0.43       131\n",
      "          R       0.50      0.56      0.53       102\n",
      "          V       1.00      0.07      0.14       110\n",
      "\n",
      "avg / total       0.53      0.41      0.35       598\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kun\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import sklearn # noqa\n",
    "from sklearn.model_selection import ShuffleSplit  # noqa\n",
    "from sklearn.svm import SVC  # noqa\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression(C=1)\n",
    "\n",
    "y = labels_new\n",
    "X = epochs_new\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "# Define a monte-carlo cross-validation generator (reduce variance):\n",
    "cv = ShuffleSplit(n_splits=4, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels_new):\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    X_train = X[train_idx][:,0]\n",
    "    X_test = X[test_idx][:,0]\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # fit classifier\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we take the derivative of the time series and fit it using logistic regression.\n",
    "\n",
    "#### The result was still low, with around 53% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.185 -0.19  -0.195 -0.195 -0.19  -0.185 -0.185 -0.19  -0.2   -0.215]\n",
      "[-0.185 -0.005 -0.005  0.     0.005  0.005  0.    -0.005 -0.01  -0.015]\n"
     ]
    }
   ],
   "source": [
    "def take_diff(epochs):\n",
    "    temp = epochs.copy()\n",
    "    for i in range(epochs.shape[0]):\n",
    "        for j in range(epochs.shape[1]):\n",
    "            if j != 0:  \n",
    "                temp[i, j] = epochs[i,j] - epochs[i,j-1]\n",
    "    return temp\n",
    "\n",
    "\n",
    "epochs_diff = take_diff(epochs_new)\n",
    "print(epochs_new[0, :10, 1])      \n",
    "print(epochs_diff[0,:10, 1])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2990, 300, 2)\n",
      "Classification accuracy: 0.422659 / Chance level: 1.000000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          /       0.47      0.65      0.55       110\n",
      "          A       0.00      0.00      0.00        15\n",
      "          L       0.47      0.12      0.20       130\n",
      "          N       0.31      0.69      0.43       131\n",
      "          R       0.50      0.56      0.53       102\n",
      "          V       1.00      0.07      0.14       110\n",
      "\n",
      "avg / total       0.53      0.41      0.35       598\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kun\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(C=1)\n",
    "\n",
    "y = labels_new\n",
    "X = epochs_diff\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "# Define a monte-carlo cross-validation generator (reduce variance):\n",
    "cv = ShuffleSplit(n_splits=4, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels_new):\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    X_train = X[train_idx][:,0]\n",
    "    X_test = X[test_idx][:,0]\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # fit classifier\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are going to use convolutional neural networks to classify ECG signals.\n",
    "\n",
    "#### Since the 6 classes have to be converted from symbols to numbers, the function below is created to perform this job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def convert_sign_into_num(labels):\n",
    "    unique = np.unique(labels)\n",
    "    num = np.arange(len(unique))\n",
    "    zipped = dict(zip(unique, num))\n",
    "    labels_num = []\n",
    "    for i in labels:\n",
    "        labels_num.append(zipped[i])\n",
    "    return labels_num\n",
    "\n",
    "labels_num = convert_sign_into_num(labels_new)\n",
    "print( len(np.unique(labels_new)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The architecture of the CNN consists of two, 1-D convolution layers, 1 max pooling layer and 2 fully-connected neural networks.\n",
    "\n",
    "#### Tuning the batch size in our case is crucial to gettting a high accuracy.\n",
    "\n",
    "#### When the batch size is 64, the accuracy on testing samples is 67%.\n",
    "\n",
    "#### When the batch size is 32, the accuracy on testing samples is 76%.\n",
    "\n",
    "#### When the batch size is 8, the accuracy on testing samples is 90%.\n",
    "\n",
    "#### When the batch size is 1, the accuracy on testing samples is 71%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2392, 300, 2)\n",
      "(2392, 300, 2)\n",
      "Train on 2392 samples, validate on 598 samples\n",
      "Epoch 1/4\n",
      "2392/2392 [==============================] - 5s - loss: 1.0656 - acc: 0.6112 - val_loss: 0.5739 - val_acc: 0.8060\n",
      "Epoch 2/4\n",
      "2392/2392 [==============================] - 3s - loss: 0.6303 - acc: 0.8110 - val_loss: 0.3492 - val_acc: 0.9247\n",
      "Epoch 3/4\n",
      "2392/2392 [==============================] - 3s - loss: 0.4619 - acc: 0.8721 - val_loss: 0.3554 - val_acc: 0.9097\n",
      "Epoch 4/4\n",
      "2392/2392 [==============================] - 3s - loss: 0.4060 - acc: 0.8913 - val_loss: 0.2537 - val_acc: 0.9398\n",
      "Test loss: 0.253737823222\n",
      "Test accuracy: 0.939799330506\n",
      "(2392, 300, 2)\n",
      "(2392, 300, 2)\n",
      "Train on 2392 samples, validate on 598 samples\n",
      "Epoch 1/4\n",
      "2392/2392 [==============================] - 4s - loss: 1.2060 - acc: 0.5351 - val_loss: 0.6165 - val_acc: 0.7759\n",
      "Epoch 2/4\n",
      "2392/2392 [==============================] - 3s - loss: 0.6774 - acc: 0.7843 - val_loss: 0.4193 - val_acc: 0.8462\n",
      "Epoch 3/4\n",
      "2392/2392 [==============================] - 3s - loss: 0.5075 - acc: 0.8340 - val_loss: 0.3217 - val_acc: 0.8930\n",
      "Epoch 4/4\n",
      "2392/2392 [==============================] - 3s - loss: 0.4300 - acc: 0.8683 - val_loss: 0.2616 - val_acc: 0.9298\n",
      "Test loss: 0.261563173704\n",
      "Test accuracy: 0.929765886686\n",
      "(2392, 300, 2)\n",
      "(2392, 300, 2)\n",
      "Train on 2392 samples, validate on 598 samples\n",
      "Epoch 1/4\n",
      "2392/2392 [==============================] - 4s - loss: 1.0937 - acc: 0.6041 - val_loss: 0.6627 - val_acc: 0.7408\n",
      "Epoch 2/4\n",
      "2392/2392 [==============================] - 4s - loss: 0.6285 - acc: 0.7780 - val_loss: 0.4608 - val_acc: 0.8528\n",
      "Epoch 3/4\n",
      "2392/2392 [==============================] - 4s - loss: 0.5059 - acc: 0.8449 - val_loss: 0.4072 - val_acc: 0.8863\n",
      "Epoch 4/4\n",
      "2392/2392 [==============================] - 3s - loss: 0.4276 - acc: 0.8641 - val_loss: 0.3178 - val_acc: 0.9214\n",
      "Test loss: 0.317845326303\n",
      "Test accuracy: 0.921404681676\n",
      "(2392, 300, 2)\n",
      "(2392, 300, 2)\n",
      "Train on 2392 samples, validate on 598 samples\n",
      "Epoch 1/4\n",
      "2392/2392 [==============================] - 4s - loss: 1.0401 - acc: 0.6125 - val_loss: 0.7511 - val_acc: 0.7609\n",
      "Epoch 2/4\n",
      "2392/2392 [==============================] - 4s - loss: 0.6526 - acc: 0.7784 - val_loss: 0.4919 - val_acc: 0.8428\n",
      "Epoch 3/4\n",
      "2392/2392 [==============================] - 3s - loss: 0.5036 - acc: 0.8503 - val_loss: 0.4047 - val_acc: 0.8880\n",
      "Epoch 4/4\n",
      "2392/2392 [==============================] - 3s - loss: 0.4083 - acc: 0.8783 - val_loss: 0.3253 - val_acc: 0.9064\n",
      "Test loss: 0.325287045593\n",
      "Test accuracy: 0.906354516047\n",
      "Classification accuracy: 0.924331 \n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "cv = ShuffleSplit(n_splits=4, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "labels = np.array(labels_num)\n",
    "epochs_data = epochs_new\n",
    "\n",
    "\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels):\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "\n",
    "\n",
    "    num_train = X_train.shape[0]\n",
    "    num_test = X_test.shape[0]\n",
    "    print(X_train.shape)\n",
    "    \n",
    "#     X_train = np.swapaxes(X_train, 1, 2)\n",
    "#     X_test = np.swapaxes(X_test, 1, 2)\n",
    "\n",
    "    print(X_train.shape)\n",
    "\n",
    "    num_classes = 6\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(8, kernel_size=(30),\n",
    "                     activation='relu',\n",
    "                     input_shape=(300,2)))\n",
    "    model.add(Conv1D(8, kernel_size=(30), activation='relu'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=4,\n",
    "              epochs=4,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    scores.append(score[1])\n",
    "\n",
    "# Printing the results\n",
    "print(\"Classification accuracy: %f \" % (np.mean(scores)))\n",
    "\n",
    "#after including only 6 classes, the acc went from 59 to 69!\n",
    "#if we change batch size from 64 to 32, teh acc went up from 67 to 76!\n",
    "#when we change the batch size to 8, the acc is 90%\n",
    "#when batch size is 4, the acc is 92%\n",
    "#when batch size is 8 and epochs is 10, the acc is 93%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN is known to work well on object detecting in image. The problem with the naive approachs is that little shift in time series can cause great variation in classification. The classification should be time-invariant, this is why we use CNN. One dimensional CNN allows us to detect pattern no matter the order of the signal. \n",
    "\n",
    "#### Since each epoch is of length 300, it makes sense to use a filter of length 30. Since there are five peaks in ecg as shown in the picture below, there should be at least 5 filters. In our case, we choose 8 filters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\n",
    "\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
